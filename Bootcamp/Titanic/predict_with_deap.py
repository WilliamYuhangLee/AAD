import operator

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from deap import creator, base, gp, tools, algorithms

######################
# PREPROCESSING DATA #
######################

# Raw data
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# Drop columns that are not useful for now
dropped = {"columns": ["Name", "Ticket", "Cabin"], "inplace": True}
train_data.drop(**dropped)
test_data.drop(**dropped)

# Set primary key (and separate it from the rest of columns)
primary_key = {"keys": ["PassengerId"], "drop": True, "inplace": True}
train_data.set_index(**primary_key)
test_data.set_index(**primary_key)

# Translate string values to int values
translations = {"Embarked": {"C": 0, "Q": 1, "S": 2}, "Sex": {"male": 0, "female": 1}}
train_data.replace(translations, inplace=True)
test_data.replace(translations, inplace=True)


# Fill in substitute values for the missing data
def fill_missing(data_set):
    # Columns that need to be filled with substitute values
    target_columns = ["Age", "Fare", "Embarked"]
    replace_map = {column: data_set[column].mean() for column in target_columns}
    data_set.fillna(value=replace_map, inplace=True)


fill_missing(train_data)
fill_missing(test_data)

# Separate x and y columns
x_train = train_data.loc[:, train_data.columns != "Survived"]
y_train = train_data.loc[:, "Survived"]

# Split a part of training data as test data (to avoid using test_data for testing)
x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=10)

# print(x_train)
# print(x_train.shape[1])
# print(x_train.values)
# print(y_train)
# print(y_train.shape[1])
# print(y_train.values)

##################
# TRAINING MODEL #
##################

# Create Fitness class
creator.create("FitnessClassification", base.Fitness, weights=(-1, -1))  # Maximize TPR, TNR, minimize FPR, FNR

# Create Individual class
creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessClassification)

# Initialize a primitive set that contains all the primitives we can use
primitive_set = gp.PrimitiveSet("main", x_train.shape[1])
primitive_set.addPrimitive(np.add, arity=2)
primitive_set.addPrimitive(np.subtract, arity=2)
primitive_set.addPrimitive(np.multiply, arity=2)
primitive_set.addPrimitive(np.power, arity=2)
primitive_set.addPrimitive(np.negative, arity=1)
primitive_set.addPrimitive(np.square, arity=1)
primitive_set.addPrimitive(np.absolute, arity=1)

# Rename arguments
primitive_set.renameArguments(ARG0='Pclass')
primitive_set.renameArguments(ARG1='Sex')
primitive_set.renameArguments(ARG2='Age')
primitive_set.renameArguments(ARG3='Sibsp')
primitive_set.renameArguments(ARG4='Parch')
primitive_set.renameArguments(ARG5='Fare')
primitive_set.renameArguments(ARG6='Embarked')

# Define toolbox
toolbox = base.Toolbox()

# gp.genHalfAndHalf() generates full syntax tree for half the time, where leaves all have the same depth
# min_ and max_ are the depth limits of the syntax tree
toolbox.register("expr", gp.genHalfAndHalf, pset=primitive_set, min_=1, max_=5)

# Fill an Individual (a PrimitiveTree container) with expressions generated by gp.genHalfAndHalf
toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)

# Generate a population by filling a list with Individuals
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

# Calling toolbox.compile(expr) will return a function that evaluates the expr when given correct number of parameters
toolbox.register("compile", gp.compile, pset=primitive_set)


# Evaluate the fitness of an Individual by testing it with validation set (x is a panda DF, y is a list of values)
def evaluate_individual_fitness(individual, x, y):
    # Compile the Individual (a PrimitiveTree) into an executable function
    func = toolbox.compile(individual)
    y_predictions = []  # hold results

    # Predict for each row (passenger)
    for row in x.values:
        result = func(*row)
        result = 1 if result >= 0 else 0
        y_predictions.append(result)

    # Get TN, FP, FN, TP from the confusion matrix
    tn, fp, fn, tp = confusion_matrix(y, y_predictions).ravel()

    # Calculate accuracy rates
    # tpr = tp / (tp + fn)
    # tnr = tn / (tn + fp)
    fpr = fp / (fp + tn)
    fnr = fn / (fn + tp)

    return fpr, fnr


# Register genetic operators
toolbox.register("evaluate", evaluate_individual_fitness, x=x_train, y=y_train)
toolbox.register("select", tools.selTournament, tournsize=3)
toolbox.register("mate", gp.cxOnePoint)
toolbox.register("expr_mut", gp.genFull, min_=0, max_=2)
toolbox.register("mutate", gp.mutUniform, expr=toolbox.expr_mut, pset=primitive_set)

# Add tree height constraints to crossover and mutation functions
toolbox.decorate("mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=20))
toolbox.decorate("mutate", gp.staticLimit(key=operator.attrgetter("height"), max_value=20))


# # Returns true if the first individual dominates the second individual
# def pareto_dominance(ind1, ind2):
#     not_equal = False
#     for value1, value2 in zip(ind1.fitness.values, ind2.fitness.values):
#         if value1 > value2:
#             return False
#         elif value1 < value2:
#             not_equal = True
#     return not_equal
#
#
# # Initialize a random population of 300
# pop = toolbox.population(n=300)
#
# # Evaluate the entire population
# fitnesses = list(map(toolbox.evaluate, pop))
# for ind, fit in zip(pop, fitnesses):
#     ind.fitness.values = fit
#
# # Initialize a separate individual for comparison
# a_given_individual = toolbox.population(n=1)[0]
# a_given_individual.fitness.values = toolbox.evaluate(a_given_individual)
#
# # Sort the population by pareto dominance in comparison to the separate individual
# dominated = [ind for ind in pop if pareto_dominance(a_given_individual, ind)]
# dominators = [ind for ind in pop if pareto_dominance(ind, a_given_individual)]
# others = [ind for ind in pop if not ind in dominated and not ind in dominators]
#
# # Plot the objective space using sorted population
# for ind in dominators:
#     plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'r.', alpha=0.7)
# for ind in dominated:
#     plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'g.', alpha=0.7)
# for ind in others:
#     plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'k.', alpha=0.7, ms=3)
# plt.plot(a_given_individual.fitness.values[0], a_given_individual.fitness.values[1], 'bo', ms=6)
# plt.xlabel('Mean Squared Error');plt.ylabel('Tree Size')
# plt.title('Objective space')
# plt.tight_layout()
# plt.show()

# Main evolutionary algorithm
NGEN = 60  # number of generations
MU = 50  # size of population
LAMBDA = 100  # number of children to produce at each generation
CXPB = 0.5  # probability that an offspring is produced by crossover
MUTPB = 0.2  # probability that an offspring is produced by mutation

pop = toolbox.population(n=MU)
hof = tools.ParetoFront()
stats = tools.Statistics(lambda ind: ind.fitness.values)
stats.register("avg", np.mean, axis=0)
stats.register("std", np.std, axis=0)
stats.register("min", np.min, axis=0)
stats.register("max", np.max, axis=0)

pop, logbook = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN, stats, halloffame=hof)

# Get the best individual
best_individual = hof[0]

# Plot the result of out run and display the best individual
print("Best individual is: %s\nwith fitness: %s" % (best_individual, best_individual.fitness))
gen, avg, min_, max_ = logbook.select("gen", "avg", "min", "max")
plt.plot(gen, np.mean(avg, axis=1), label="average")
plt.plot(gen, np.mean(min_, axis=1), label="minimum")
plt.xlabel("Generation")
plt.ylabel("Average Fitness Values")
plt.legend(loc="upper left")
plt.show()

# Split fitness values into separate lists
fitness_1 = [ind.fitness.values[0] for ind in hof]
fitness_2 = [ind.fitness.values[1] for ind in hof]
pop_1 = [ind.fitness.values[0] for ind in pop]
pop_2 = [ind.fitness.values[1] for ind in pop]

# Print dominated population for debugging
# for ind in pop:
#     print(ind.fitness)

plt.scatter(pop_1, pop_2, color='b')
plt.scatter(fitness_1, fitness_2, color='r')
plt.plot(fitness_1, fitness_2, color='r', drawstyle='steps-post')
plt.xlabel("FPR")
plt.ylabel("FNR")
plt.title("Pareto Front")
plt.show()

f1 = np.array(fitness_1)
f2 = np.array(fitness_2)

# Calculate area under curve with least squares method
print("Area Under Curve: %s" % (np.sum(np.abs(np.diff(f1))*f2[:-1])))

# Show stats for the best individual
fpr, fnr = evaluate_individual_fitness(best_individual, x_validation, y_validation)
print("")
print("Best individual stats:")
print("FPR:", fpr)
print("FNR:", fnr)
